{"repo_name":"lisroach\/PyRESTCONF","path":"rest_calls\/tests\/unit\/test_xml_mock.py","copies":"1","size":"2194","content":"import unittest\r\nimport requests\r\nimport mock\r\n\r\nfrom rest_calls.xmlRestClient import XMLRestCalls\r\n\r\nusername = 'admin'\r\npassword = 'admin'\r\nip = '127.0.0.1'\r\nport = 80\r\nendpoint = 'Cisco-IOS-XR-ip-static-cfg:router-static'\r\nsm_url = '{scheme}:\/\/{ip}:{port}{basePath}\/'.format(\r\n    scheme='http',\r\n    ip=ip,\r\n    port=port,\r\n    basePath='\/restconf\/data'\r\n)\r\nurl = sm_url + endpoint\r\ncontents = '{test: test}'\r\n\r\n\r\nclass XMLRestCallsCase(unittest.TestCase):\r\n    def setUp(self):\r\n        self.classObject = XMLRestCalls(\r\n            ip,\r\n            port,\r\n            username,\r\n            password\r\n        )\r\n\r\n    def test__init__(self):\r\n        \"\"\"Does constructor create a proper object\"\"\"\r\n        session = requests.Session()\r\n        session.headers.update({\r\n            'Accept': ','.join([\r\n                'application\/yang.data+xml',\r\n                'application\/yang.errors+xml',\r\n                ]),\r\n            'Content-Type': 'application\/yang.data+xml',\r\n        })\r\n        self.assertEqual(self.classObject._session.headers,\r\n                         session.headers)\r\n        self.assertEqual(self.classObject._host, sm_url)\r\n\r\n    @mock.patch('requests.sessions.Session.get')\r\n    def test_get(self, mock_get):\r\n        self.classObject.get(endpoint)\r\n        mock_get.assert_called_once_with(url, params={})\r\n\r\n    @mock.patch('requests.sessions.Session.put')\r\n    def test_put(self, mock_put):\r\n        self.classObject.put(contents, endpoint)\r\n        mock_put.assert_called_once_with(url, data=contents)\r\n\r\n    @mock.patch('requests.sessions.Session.patch')\r\n    def test_patch(self, mock_patch):\r\n        self.classObject.patch(contents, endpoint)\r\n        mock_patch.assert_called_once_with(url, data=contents)\r\n\r\n    @mock.patch('requests.sessions.Session.post')\r\n    def test_post(self, mock_post):\r\n        self.classObject.post(contents, endpoint)\r\n        mock_post.assert_called_once_with(url, data=contents)\r\n\r\n    @mock.patch('requests.sessions.Session.delete')\r\n    def test_delete(self, mock_delete):\r\n        self.classObject.delete(endpoint)\r\n        mock_delete.assert_called_once_with(url)\r\n\r\nif __name__ == \"__main__\":\r\n    unittest.main()\r\n","license":"apache-2.0","hash":5605707288026969549,"line_mean":28.9014084507,"line_max":62,"alpha_frac":0.6020966272,"autogenerated":false}
{"repo_name":"igatoolsProject\/igatools","path":"source\/geometry\/grid.inst.py","copies":"1","size":"2551","content":"#-+--------------------------------------------------------------------\n# Igatools a general purpose Isogeometric analysis library.\n# Copyright (C) 2012-2016  by the igatools authors (see authors.txt).\n#\n# This file is part of the igatools library.\n#\n# The igatools library is free software: you can use it, redistribute\n# it and\/or modify it under the terms of the GNU General Public\n# License as published by the Free Software Foundation, either\n# version 3 of the License, or (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http:\/\/www.gnu.org\/licenses\/>.\n#-+--------------------------------------------------------------------\n\nfrom init_instantiation_data import *\n\ninclude_files = ['geometry\/grid_element.h']\ndata = Instantiation(include_files)\n(f, inst) = (data.file_output, data.inst)\n\nsub_dim_members = ['Grid<dim>::template BoundaryNormals<k> ' +\n                   'Grid<dim>::get_boundary_normals<k>(const int s_id) const;',\n                   'std::shared_ptr<Grid<k>> Grid<dim>::'+\n                   'get_sub_grid<k>(const int sub_elem_id, typename Grid<dim>::template SubGridMap<k> &elem_map) const;']\n\ngrids = [] \nfor dim in inst.sub_domain_dims:\n    grid = 'Grid<%d>' %(dim)\n    grids.append(grid)\n    f.write('template class %s; \\n' % (grid))\n    for fun in sub_dim_members:\n        for k in range(0,max(dim-1,0)+1):\n#        k = dim\n            s = fun.replace('k', '%d' % (k)).replace('dim', '%d' % (dim));\n            f.write('template ' + s + '\\n')  \n    \nfor dim in inst.domain_dims:\n    grid = 'Grid<%d>' %(dim)   \n    grids.append(grid)\n    f.write('template class %s; \\n' % (grid))\n    for fun in sub_dim_members:\n        for k in range(0,max(dim-1,0)+1):\n#        for k in inst.sub_dims(dim):\n            s = fun.replace('k', '%d' % (k)).replace('dim', '%d' % (dim));\n            f.write('template ' + s + '\\n')\n       \n\n\n\n#---------------------------------------------------\nf.write('#ifdef IGATOOLS_WITH_SERIALIZATION\\n')\narchives = ['OArchive','IArchive']\n\nfor grid in unique(grids):\n    for ar in archives:\n        f.write('template void %s::serialize(%s&);\\n' %(grid,ar))\nf.write('#endif \/\/ IGATOOLS_WITH_SERIALIZATION\\n')\n#---------------------------------------------------\n","license":"gpl-3.0","hash":-6941081620431806906,"line_mean":38.859375,"line_max":121,"alpha_frac":0.5711485692,"autogenerated":false}
{"repo_name":"thundernet8\/Plog","path":"app\/core\/main\/views.py","copies":"1","size":"4256","content":"# coding=utf-8\n\nfrom datetime import datetime\nimport json\n\nfrom flask import current_app\nfrom flask import send_file\nfrom flask import request\nfrom flask import render_template\nfrom flask import session\nfrom flask import redirect\nfrom flask import abort\nfrom flask.ext.login import current_user\n\nfrom . import main\nfrom app.core.models.helpers.redis_cache_decorator import redis_cached\nfrom app.core.models.settings import Setting\nfrom app.core.models.posts import Post\nfrom app.core.models.posts import Posts\nfrom app.core.models.users import User\nfrom app.core.models.tags import Tag\nfrom .forms import CommentForm\n\n\n@main.route('\/favicon.ico')\ndef favicon():\n    \"\"\"\n    \u6536\u85cf\u5939\u680f\u56fe\u6807\n    :return:\n    \"\"\"\n    return send_file('static\/dist\/images\/favicon.ico', as_attachment=False)\n\n\n@main.route('\/kill-ie.html')\ndef kill_ie():\n    \"\"\"\n    kill ie\n    :return:\n    \"\"\"\n    return render_template('utils\/kill-ie.html', blog_name=Setting.get_setting('blog_name', 'Plog'))\n\n\n# \u641c\u7d22\n@main.route('\/search', methods=['GET', 'POST'])\ndef search():\n    if request.method == 'POST':\n        s = request.form.get('s')\n        return redirect('\/search?s='+s)\n    else:\n        s = request.args.get('s')\n    return s  # TODO search\n\n\n# \u9996\u9875\n@main.route('\/')\n@redis_cached(timeout=30, key_prefix='home_html')  # TODO \u7f13\u5b58\u65f6\u95f4\ndef index():\n    pagenation = Posts(filters={'status': 'published'}).pagination()\n    posts = pagenation.items if pagenation else []\n    return render_template('home.html', posts=posts, pagenation=pagenation)\n\n\n# \u9996\u9875(\u5e26\u5206\u9875)\n@main.route('\/page\/<int:page>')\n@redis_cached(timeout=30, key_prefix='home_html_%s')\ndef index_paged(page):\n    pagenation = Posts(filters={'status': 'published'}).pagination(page=page)\n    posts = pagenation.items if pagenation else []\n    return render_template('home.html', posts=posts, pagenation=pagenation)\n\n\n# \u6587\u7ae0\u8be6\u60c5\u9875\n@main.route('\/article\/<int:post_id>.html')\n@redis_cached(timeout=30, key_prefix='article_%s')\ndef article_detail(post_id):\n    post = Post.get_post(post_id)\n    if not post or not post.post_id or post.status != 'published':\n        abort(404)\n    author = User(user_id=post.author_id)\n    comment_form = CommentForm()\n    return render_template('article.html', post=post, author=author, comment_form=comment_form)\n\n\n# \u7528\u6237\/\u4f5c\u8005\u4e3b\u9875\n@main.route('\/author\/<int:user_id>')\n@redis_cached(timeout=300, key_prefix='author_%s')\ndef user_homepage(user_id):\n    author = User.get_user_by_id(user_id)\n    if not author:\n        abort(404)\n    pagenation = User.get_user_posts_pagenation(user_id)\n    posts = pagenation.items if pagenation else []\n    return render_template('author.html', author=author, posts=posts, pagenation=pagenation)  # TODO \/\u8003\u8651\u4f7f\u7528\u7528\u6237\u540d\u6216\u6635\u79f0\u66ff\u4ee3\u7528\u6237 id \u4f5c\u4e3a\u94fe\u63a5\u6807\u8bc6\n\n\n# \u7528\u6237\/\u4f5c\u8005\u4e3b\u9875(\u5e26\u5206\u9875)\n@main.route('\/author\/<int:user_id>\/page\/<int:page>')\n@redis_cached(timeout=300, key_prefix='author_%s')\ndef user_homepage_paged(user_id, page):\n    author = User.get_user_by_id(user_id)\n    if not author:\n        abort(404)\n    pagenation = User.get_user_posts_pagenation(user_id, page=page)\n    posts = pagenation.items if pagenation else []\n    return render_template('author.html', author=author, posts=posts, pagenation=pagenation)\n\n\n# RSS\n@main.route('\/rss')\n@redis_cached(timeout=600, key_prefix='rss')\ndef rss():\n    return 'rss'  # TODO rss\n\n\n# TAG\n@main.route('\/tag\/<int:tag_id>')\n@redis_cached(timeout=600, key_prefix='tag_%s')\ndef tag(tag_id):\n    tag = Tag.get_tag_by_id(tag_id)\n    if not tag:\n        abort(404)\n    pagenation = Tag.get_tag_posts(tag_id)\n    posts = pagenation.items if pagenation else []\n    return render_template('tag.html', tag=tag, posts=posts, pagenation=pagenation)\n\n\n# TAG(\u5e26\u5206\u9875)\n@main.route('\/tag\/<int:tag_id>\/page\/<int:page>')\n@redis_cached(timeout=600, key_prefix='tag_%s')\ndef tag_paged(tag_id, page):\n    tag = Tag.get_tag_by_id(tag_id)\n    if not tag:\n        abort(404)\n    pagenation = Tag.get_tag_posts(tag_id, page=page)\n    posts = pagenation.items if pagenation else []\n    return render_template('tag.html', tag=tag, posts=posts, pagenation=pagenation)\n\n\n# 404\n@main.errorhandler(404)\ndef main_404(e):\n    return render_template('error_pages\/404.html'), 404\n\n\n\n\n\n","license":"gpl-3.0","hash":2699200856079543198,"line_mean":27.1088435374,"line_max":126,"alpha_frac":0.6878025169,"autogenerated":false}
{"repo_name":"lmazuel\/azure-sdk-for-python","path":"azure-mgmt-datalake-analytics\/azure\/mgmt\/datalake\/analytics\/account\/models\/compute_policy.py","copies":"1","size":"2664","content":"# coding=utf-8\n# --------------------------------------------------------------------------\n# Copyright (c) Microsoft Corporation. All rights reserved.\n# Licensed under the MIT License. See License.txt in the project root for\n# license information.\n#\n# Code generated by Microsoft (R) AutoRest Code Generator.\n# Changes may cause incorrect behavior and will be lost if the code is\n# regenerated.\n# --------------------------------------------------------------------------\n\nfrom .sub_resource import SubResource\n\n\nclass ComputePolicy(SubResource):\n    \"\"\"Data Lake Analytics compute policy information.\n\n    Variables are only populated by the server, and will be ignored when\n    sending a request.\n\n    :ivar id: The resource identifier.\n    :vartype id: str\n    :ivar name: The resource name.\n    :vartype name: str\n    :ivar type: The resource type.\n    :vartype type: str\n    :ivar object_id: The AAD object identifier for the entity to create a\n     policy for.\n    :vartype object_id: str\n    :ivar object_type: The type of AAD object the object identifier refers to.\n     Possible values include: 'User', 'Group', 'ServicePrincipal'\n    :vartype object_type: str or\n     ~azure.mgmt.datalake.analytics.account.models.AADObjectType\n    :ivar max_degree_of_parallelism_per_job: The maximum degree of parallelism\n     per job this user can use to submit jobs.\n    :vartype max_degree_of_parallelism_per_job: int\n    :ivar min_priority_per_job: The minimum priority per job this user can use\n     to submit jobs.\n    :vartype min_priority_per_job: int\n    \"\"\"\n\n    _validation = {\n        'id': {'readonly': True},\n        'name': {'readonly': True},\n        'type': {'readonly': True},\n        'object_id': {'readonly': True},\n        'object_type': {'readonly': True},\n        'max_degree_of_parallelism_per_job': {'readonly': True, 'minimum': 1},\n        'min_priority_per_job': {'readonly': True, 'minimum': 1},\n    }\n\n    _attribute_map = {\n        'id': {'key': 'id', 'type': 'str'},\n        'name': {'key': 'name', 'type': 'str'},\n        'type': {'key': 'type', 'type': 'str'},\n        'object_id': {'key': 'properties.objectId', 'type': 'str'},\n        'object_type': {'key': 'properties.objectType', 'type': 'str'},\n        'max_degree_of_parallelism_per_job': {'key': 'properties.maxDegreeOfParallelismPerJob', 'type': 'int'},\n        'min_priority_per_job': {'key': 'properties.minPriorityPerJob', 'type': 'int'},\n    }\n\n    def __init__(self):\n        super(ComputePolicy, self).__init__()\n        self.object_id = None\n        self.object_type = None\n        self.max_degree_of_parallelism_per_job = None\n        self.min_priority_per_job = None\n","license":"mit","hash":5015207261158012778,"line_mean":38.7611940299,"line_max":111,"alpha_frac":0.6024774775,"autogenerated":false}
{"repo_name":"tobetter\/linaro-image-tools_packaging","path":"linaro_image_tools\/utils.py","copies":"1","size":"13217","content":"# Copyright (C) 2010, 2011 Linaro\n#\n# Author: Guilherme Salgado <guilherme.salgado@linaro.org>\n#\n# This file is part of Linaro Image Tools.\n#\n# Linaro Image Tools is free software: you can redistribute it and\/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Linaro Image Tools is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Linaro Image Tools.  If not, see <http:\/\/www.gnu.org\/licenses\/>.\n\nimport os\nimport platform\nimport subprocess\nimport re\nimport logging\nimport tempfile\nimport tarfile\nimport sys\n\nfrom linaro_image_tools import cmd_runner\n\nDEFAULT_LOGGER_NAME = 'linaro_image_tools'\n\n# The boot path in the boot tarball.\nBOOT_DIR_IN_TARBALL = \"boot\"\n# The name of the hwpack file found in the boot tarball.\nHWPACK_NAME = \"config\"\n\n\n# try_import was copied from python-testtools 0.9.12 and was originally\n# licensed under a MIT-style license but relicensed under the GPL in Linaro\n# Image Tools.\n# Copyright (c) 2011 Jonathan M. Lange <jml@mumak.net>.\ndef try_import(name, alternative=None, error_callback=None):\n    \"\"\"Attempt to import ``name``.  If it fails, return ``alternative``.\n\n    When supporting multiple versions of Python or optional dependencies, it\n    is useful to be able to try to import a module.\n\n    :param name: The name of the object to import, e.g. ``os.path`` or\n        ``os.path.join``.\n    :param alternative: The value to return if no module can be imported.\n        Defaults to None.\n    :param error_callback: If non-None, a callable that is passed the\n        ImportError when the module cannot be loaded.\n    \"\"\"\n    module_segments = name.split('.')\n    last_error = None\n    while module_segments:\n        module_name = '.'.join(module_segments)\n        try:\n            module = __import__(module_name)\n        except ImportError:\n            last_error = sys.exc_info()[1]\n            module_segments.pop()\n            continue\n        else:\n            break\n    else:\n        if last_error is not None and error_callback is not None:\n            error_callback(last_error)\n        return alternative\n    nonexistent = object()\n    for segment in name.split('.')[1:]:\n        module = getattr(module, segment, nonexistent)\n        if module is nonexistent:\n            if last_error is not None and error_callback is not None:\n                error_callback(last_error)\n            return alternative\n    return module\n\n\nCommandNotFound = try_import('CommandNotFound.CommandNotFound')\n\n\ndef path_in_tarfile_exists(path, tar_file):\n    exists = True\n    try:\n        tarinfo = tarfile.open(tar_file, 'r:gz')\n        tarinfo.getmember(path)\n        tarinfo.close()\n    except KeyError:\n        exists = False\n    finally:\n        return exists\n\n\ndef verify_file_integrity(sig_file_list):\n    \"\"\"Verify a list of signature files.\n\n    The parameter is a list of filenames of gpg signature files which will be\n    verified using gpg. For each of the files it is assumed that there is an\n    sha1 hash file with the same file name minus the '.asc' extension.\n\n    Each of the sha1 files will be checked using sha1sums. All files listed in\n    the sha1 hash file must be found in the same directory as the hash file.\n    \"\"\"\n\n    gpg_sig_ok = True\n    gpg_out = \"\"\n\n    verified_files = []\n    for sig_file in sig_file_list:\n        hash_file = sig_file[0:-len('.asc')]\n        tmp = tempfile.NamedTemporaryFile()\n\n        try:\n            cmd_runner.run(['gpg', '--status-file={0}'.format(tmp.name),\n                            '--verify', sig_file]).wait()\n        except cmd_runner.SubcommandNonZeroReturnValue:\n            gpg_sig_ok = False\n            gpg_out = gpg_out + tmp.read()\n\n        tmp.close()\n\n        if os.path.dirname(hash_file) == '':\n            sha_cwd = None\n        else:\n            sha_cwd = os.path.dirname(hash_file)\n\n        try:\n            sha1sums_out, _ = cmd_runner.Popen(\n                ['sha1sum', '-c', hash_file],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.STDOUT,\n                cwd=sha_cwd\n            ).communicate()\n        except cmd_runner.SubcommandNonZeroReturnValue as inst:\n            sha1sums_out = inst.stdout\n\n        for line in sha1sums_out.splitlines():\n            sha1_check = re.search(r'^(.*):\\s+OK', line)\n            if sha1_check:\n                verified_files.append(sha1_check.group(1))\n\n    return verified_files, gpg_sig_ok, gpg_out\n\n\ndef check_file_integrity_and_log_errors(sig_file_list, binary, hwpacks):\n    \"\"\"\n    Wrapper around verify_file_integrity that prints error messages to stderr\n    if verify_file_integrity finds any problems.\n    \"\"\"\n    verified_files, gpg_sig_pass, _ = verify_file_integrity(sig_file_list)\n\n    # Check the outputs from verify_file_integrity\n    # Abort if anything fails.\n    logger = logging.getLogger(__name__)\n    if len(sig_file_list):\n        if not gpg_sig_pass:\n            logger.error(\"GPG signature verification failed.\")\n            return False, []\n\n        if not os.path.basename(binary) in verified_files:\n            logger.error(\"OS Binary verification failed\")\n            return False, []\n\n        for hwpack in hwpacks:\n            if not os.path.basename(hwpack) in verified_files:\n                logger.error(\"Hwpack {0} verification failed\".format(hwpack))\n                return False, []\n\n        for verified_file in verified_files:\n            logger.info('Hash verification of file {0} OK.'.format(\n                verified_file))\n    return True, verified_files\n\n\ndef install_package_providing(command):\n    \"\"\"Install a package which provides the given command.\n\n    If we can't find any package which provides it, raise\n    UnableToFindPackageProvidingCommand.\n\n    If the user denies installing the package, the program exits.\n    \"\"\"\n\n    if CommandNotFound is None:\n        raise UnableToFindPackageProvidingCommand(\n            \"CommandNotFound python module does not exist.\")\n\n    packages = CommandNotFound().getPackages(command)\n    if len(packages) == 0:\n        raise UnableToFindPackageProvidingCommand(\n            \"Unable to find any package providing %s\" % command)\n\n    # TODO: Ask the user to pick a package when there's more than one that\n    # provides the given command.\n    package, _ = packages[0]\n    output, _ = cmd_runner.run(['apt-get', '-s', 'install', package],\n                               stdout=subprocess.PIPE).communicate()\n    to_install = []\n    for line in output.splitlines():\n        if line.startswith(\"Inst\"):\n            to_install.append(line.split()[1])\n    if not to_install:\n        raise UnableToFindPackageProvidingCommand(\n            \"Unable to find any package to be installed.\")\n\n    try:\n        print (\"In order to use the '%s' command, the following package\/s \"\n               \"have to be installed: %s\" % (command, \" \".join(to_install)))\n        resp = raw_input(\"Install? (Y\/n) \")\n        if resp.lower() != 'y':\n            print \"Package installation is necessary to continue. Exiting.\"\n            sys.exit(1)\n        print (\"Installing required command '%s' from package '%s'...\"\n               % (command, package))\n        cmd_runner.run(['apt-get', '--yes', 'install', package],\n                       as_root=True).wait()\n    except EOFError:\n        raise PackageInstallationRefused(\n            \"Package installation interrupted: input error.\")\n    except KeyboardInterrupt:\n        raise PackageInstallationRefused(\n            \"Package installation interrupted by the user.\")\n\n\ndef has_command(command):\n    \"\"\"Check the given command is available.\"\"\"\n    try:\n        cmd_runner.run(\n            ['which', command], stdout=open('\/dev\/null', 'w')).wait()\n        return True\n    except cmd_runner.SubcommandNonZeroReturnValue:\n        return False\n\n\ndef ensure_command(command):\n    \"\"\"Ensure the given command is available.\n\n    If it's not, look up a package that provides it and install that.\n    \"\"\"\n    if not has_command(command):\n        install_package_providing(command)\n\n\ndef find_command(name, prefer_dir=None):\n    \"\"\"Finds a linaro-image-tools command.\n\n    Prefers specified directory, otherwise searches only the current directory\n    when running from a checkout, or only PATH when running from an installed\n    version.\n    \"\"\"\n    assert name != \"\"\n    assert os.path.dirname(name) == \"\"\n\n    cmd_runner.sanitize_path(os.environ)\n\n    # default to searching in current directory when running from a bzr\n    # checkout\n    dirs = [os.getcwd(), ]\n    if os.path.isabs(__file__):\n        dirs = os.environ[\"PATH\"].split(os.pathsep)\n        # empty dir in PATH means current directory\n        dirs = map(lambda x: x == '' and '.' or x, dirs)\n\n    if prefer_dir is not None:\n        dirs.insert(0, prefer_dir)\n\n    for dir in dirs:\n        path = os.path.join(dir, name)\n        if os.path.exists(path) and os.access(path, os.X_OK):\n            return path\n\n    return None\n\n\ndef is_arm_host():\n    return platform.machine().startswith('arm')\n\n\ndef preferred_tools_dir():\n    prefer_dir = None\n    # running from bzr checkout?\n    if not os.path.isabs(__file__):\n        prefer_dir = os.getcwd()\n    return prefer_dir\n\n\ndef prep_media_path(args):\n    if args.directory is not None:\n        loc = os.path.abspath(args.directory)\n        try:\n            os.makedirs(loc)\n        except OSError:\n            # Directory exists.\n            pass\n\n        path = os.path.join(loc, args.device)\n    else:\n        path = args.device\n\n    return path\n\n\nclass UnableToFindPackageProvidingCommand(Exception):\n    \"\"\"We can't find a package which provides the given command.\"\"\"\n\n\nclass PackageInstallationRefused(Exception):\n    \"\"\"User has chosen not to install a package.\"\"\"\n\n\nclass InvalidHwpackFile(Exception):\n    \"\"\"The hwpack parameter is not a regular file.\"\"\"\n\n\nclass MissingRequiredOption(Exception):\n    \"\"\"A required option from the command line is missing.\"\"\"\n    def __init__(self, value):\n        self.value = value\n\n    def __str__(self):\n        return repr(self.value)\n\n\nclass IncompatibleOptions(Exception):\n    def __init__(self, value):\n        self.value = value\n\n    def __str__(self):\n        return repr(self.value)\n\n\ndef additional_option_checks(args):\n    if args.directory is not None:\n    # If args.device is a path to a device (\/dev\/) then this is an error\n        if \"--mmc\" in sys.argv:\n            raise IncompatibleOptions(\"--directory option incompatible with \"\n                                      \"option --mmc\")\n\n        # If directory is used as well as having a full path (rather than just\n        # a file name or relative path) in args.device, this is an error.\n        if re.search(r\"^\/\", args.device):\n            raise IncompatibleOptions(\"--directory option incompatible with \"\n                                      \"a full path in --image-file\")\n\n    for hwpack in args.hwpacks:\n        if not os.path.isfile(hwpack):\n            raise InvalidHwpackFile(\n                \"--hwpack argument (%s) is not a regular file\" % hwpack)\n\n\ndef additional_android_option_checks(args):\n    \"\"\"Checks that some of the args passed to l-a-m-c are valid.\"\"\"\n    if args.hwpack:\n        if not os.path.isfile(args.hwpack):\n            raise InvalidHwpackFile(\n                \"--hwpack argument (%s) is not a regular file\" % args.hwpack)\n\n\ndef andorid_hwpack_in_boot_tarball(boot_dir):\n    \"\"\"Simple check for existence of a path.\n\n    Needed to make cli command testable in some way.\n    :param boot_dir: The path where the boot tarball has been extracted.\n    :type str\n    :return A tuple with a bool if the path exists, and the path to the config\n            file.\n    \"\"\"\n    conf_file = os.path.join(boot_dir, BOOT_DIR_IN_TARBALL, HWPACK_NAME)\n    return os.path.exists(conf_file), conf_file\n\n\ndef check_required_args(args):\n    \"\"\"Check that the required args are passed.\"\"\"\n    if args.dev is None:\n        raise MissingRequiredOption(\"--dev option is required\")\n    if args.binary is None:\n        raise MissingRequiredOption(\"--binary option is required\")\n\n\ndef get_logger(name=DEFAULT_LOGGER_NAME, debug=False):\n    \"\"\"\n    Retrieves a named logger. Default name is set in the variable\n    DEFAULT_LOG_NAME. Debug is set to False by default.\n\n    :param name: The name of the logger.\n    :param debug: If debug level should be turned on\n    :return: A logger instance.\n    \"\"\"\n    logger = logging.getLogger(name)\n    ch = logging.StreamHandler()\n\n    if debug:\n        ch.setLevel(logging.DEBUG)\n        formatter = logging.Formatter(\n            \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n        ch.setFormatter(formatter)\n        logger.setLevel(logging.DEBUG)\n    else:\n        ch.setLevel(logging.INFO)\n        formatter = logging.Formatter(\"%(message)s\")\n        ch.setFormatter(formatter)\n        logger.setLevel(logging.INFO)\n\n    logger.addHandler(ch)\n    return logger\n","license":"gpl-3.0","hash":8347262142669630789,"line_mean":31.3946078431,"line_max":78,"alpha_frac":0.6335023076,"autogenerated":false}
{"repo_name":"cbertinato\/pandas","path":"pandas\/io\/date_converters.py","copies":"1","size":"1865","content":"\"\"\"This module is designed for community supported date conversion functions\"\"\"\nimport numpy as np\n\nfrom pandas._libs.tslibs import parsing\n\n\ndef parse_date_time(date_col, time_col):\n    date_col = _maybe_cast(date_col)\n    time_col = _maybe_cast(time_col)\n    return parsing.try_parse_date_and_time(date_col, time_col)\n\n\ndef parse_date_fields(year_col, month_col, day_col):\n    year_col = _maybe_cast(year_col)\n    month_col = _maybe_cast(month_col)\n    day_col = _maybe_cast(day_col)\n    return parsing.try_parse_year_month_day(year_col, month_col, day_col)\n\n\ndef parse_all_fields(year_col, month_col, day_col, hour_col, minute_col,\n                     second_col):\n    year_col = _maybe_cast(year_col)\n    month_col = _maybe_cast(month_col)\n    day_col = _maybe_cast(day_col)\n    hour_col = _maybe_cast(hour_col)\n    minute_col = _maybe_cast(minute_col)\n    second_col = _maybe_cast(second_col)\n    return parsing.try_parse_datetime_components(year_col, month_col, day_col,\n                                                 hour_col, minute_col,\n                                                 second_col)\n\n\ndef generic_parser(parse_func, *cols):\n    N = _check_columns(cols)\n    results = np.empty(N, dtype=object)\n\n    for i in range(N):\n        args = [c[i] for c in cols]\n        results[i] = parse_func(*args)\n\n    return results\n\n\ndef _maybe_cast(arr):\n    if not arr.dtype.type == np.object_:\n        arr = np.array(arr, dtype=object)\n    return arr\n\n\ndef _check_columns(cols):\n    if not len(cols):\n        raise AssertionError(\"There must be at least 1 column\")\n\n    head, tail = cols[0], cols[1:]\n\n    N = len(head)\n\n    for i, n in enumerate(map(len, tail)):\n        if n != N:\n            raise AssertionError('All columns must have the same length: {0}; '\n                                 'column {1} has length {2}'.format(N, i, n))\n\n    return N\n","license":"bsd-3-clause","hash":8620790840864050110,"line_mean":28.6031746032,"line_max":79,"alpha_frac":0.5962466488,"autogenerated":false}
{"repo_name":"Digilent\/u-boot-digilent","path":"test\/py\/tests\/test_i2c.py","copies":"1","size":"1946","content":"# Copyright (c) 2015 Stephen Warren\n#\n# SPDX-License-Identifier: GPL-2.0\n\nimport pytest\nimport random\n\n@pytest.mark.buildconfigspec(\"cmd_i2c\")\ndef test_i2c_bus(u_boot_console):\n    expected_response = \"Bus\"\n    response = u_boot_console.run_command(\"i2c bus\")\n    assert(expected_response in response)\n\n@pytest.mark.buildconfigspec(\"cmd_i2c\")\ndef test_i2c_dev(u_boot_console):\n    expected_response = \"Current bus\"\n    response = u_boot_console.run_command(\"i2c dev\")\n    assert(expected_response in response)\n\n@pytest.mark.buildconfigspec(\"cmd_i2c\")\ndef test_i2c_probe(u_boot_console):\n    expected_response = \"Valid chip addresses:\"\n    response = u_boot_console.run_command(\"i2c probe\")\n    assert(expected_response in response)\n\n@pytest.mark.boardidentity(\"!qemu\")\n@pytest.mark.boardspec(\"zynq_zc702\")\n@pytest.mark.boardspec(\"zynq_zc706\")\n@pytest.mark.buildconfigspec(\"cmd_i2c\")\ndef test_i2c_probe_zc70x(u_boot_console):\n    # Enable i2c mux bridge\n    u_boot_console.run_command(\"i2c mw 74 0 4\")\n    u_boot_console.run_command(\"i2c probe\")\n    val = format(random.randint(0,255), '02x')\n    u_boot_console.run_command(\"i2c mw 54 0 \" + val + \" 5\")\n    response = u_boot_console.run_command(\"i2c md 54 0 5\")\n    expected_response = \"0000: \" + val + \" \" + val + \" \" + val + \" \" + val + \" \" + val + \" \"\n    assert(expected_response in response)\n\n@pytest.mark.boardspec(\"xilinx_zynqmp_zcu102\")\n@pytest.mark.buildconfigspec(\"cmd_i2c\")\ndef test_i2c_probe_zcu102(u_boot_console):\n    # This is using i2c mux wiring from config file\n    u_boot_console.run_command(\"i2c dev 5\")\n    u_boot_console.run_command(\"i2c probe\")\n    val = format(random.randint(0,255), '02x')\n    u_boot_console.run_command(\"i2c mw 54 0 \" + val + \" 5\")\n    response = u_boot_console.run_command(\"i2c md 54 0 5\")\n    expected_response = \"0000: \" + val + \" \" + val + \" \" + val + \" \" + val + \" \" + val + \" \"\n    print expected_response\n    assert(expected_response in response)\n","license":"gpl-2.0","hash":-4781732101770132973,"line_mean":37.1568627451,"line_max":92,"alpha_frac":0.674717369,"autogenerated":false}
{"repo_name":"JeffHoogland\/qtdesigner-pyside-tutorial","path":"tut1-mainwindow\/ui_mainWindow.py","copies":"2","size":"1602","content":"# -*- coding: utf-8 -*-\n\n# Form implementation generated from reading ui file 'mainWindow.ui'\n#\n# Created: Thu Mar 12 15:46:01 2015\n#      by: pyside-uic 0.2.15 running on PySide 1.2.1\n#\n# WARNING! All changes made in this file will be lost!\n\nfrom PySide import QtCore, QtGui\n\nclass Ui_mainWindow(object):\n    def setupUi(self, mainWindow):\n        mainWindow.setObjectName(\"mainWindow\")\n        mainWindow.resize(376, 207)\n        self.centralwidget = QtGui.QWidget(mainWindow)\n        self.centralwidget.setObjectName(\"centralwidget\")\n        self.verticalLayout = QtGui.QVBoxLayout(self.centralwidget)\n        self.verticalLayout.setObjectName(\"verticalLayout\")\n        self.goText = QtGui.QTextEdit(self.centralwidget)\n        self.goText.setEnabled(True)\n        self.goText.setTextInteractionFlags(QtCore.Qt.TextSelectableByKeyboard|QtCore.Qt.TextSelectableByMouse)\n        self.goText.setObjectName(\"goText\")\n        self.verticalLayout.addWidget(self.goText)\n        self.goButton = QtGui.QPushButton(self.centralwidget)\n        self.goButton.setObjectName(\"goButton\")\n        self.verticalLayout.addWidget(self.goButton)\n        mainWindow.setCentralWidget(self.centralwidget)\n\n        self.retranslateUi(mainWindow)\n        QtCore.QMetaObject.connectSlotsByName(mainWindow)\n\n    def retranslateUi(self, mainWindow):\n        mainWindow.setWindowTitle(QtGui.QApplication.translate(\"mainWindow\", \"Qt Designer MainWindow Example\", None, QtGui.QApplication.UnicodeUTF8))\n        self.goButton.setText(QtGui.QApplication.translate(\"mainWindow\", \"Go Button\", None, QtGui.QApplication.UnicodeUTF8))\n\n","license":"bsd-3-clause","hash":-2359122869957934119,"line_mean":43.5,"line_max":149,"alpha_frac":0.7322097378,"autogenerated":false}
{"repo_name":"bburan\/psiexperiment","path":"psi\/context\/expression.py","copies":"1","size":"3158","content":"import logging\r\nlog = logging.getLogger(__name__)\r\n\r\nfrom atom.api import Atom, Typed\r\nfrom psi.util import get_dependencies\r\n\r\n\r\nclass Expr(object):\r\n\r\n    def __init__(self, expression):\r\n        if not isinstance(expression, str):\r\n            raise ValueError('Expression must be a string')\r\n        if not expression:\r\n            raise ValueError('No value provided for expression')\r\n        self._expression = expression\r\n        self._code = compile(expression, 'dynamic', 'eval')\r\n        self._dependencies = get_dependencies(expression)\r\n\r\n    def evaluate(self, context):\r\n        return eval(self._expression, context)\r\n\r\n\r\nclass ExpressionNamespace(Atom):\r\n\r\n    _locals = Typed(dict, {})\r\n    _expressions = Typed(dict, {})\r\n    _globals = Typed(dict, {})\r\n\r\n    def __init__(self, expressions=None, globals=None):\r\n        if globals is None:\r\n            globals = {}\r\n        if expressions is None:\r\n            expressions = {}\r\n        self._locals = {}\r\n        self._globals = globals\r\n        self._expressions = {k: Expr(str(v)) for k, v in expressions.items()}\r\n\r\n    def update_expressions(self, expressions):\r\n        self._expressions.update({k: Expr(str(v)) for k, v in expressions.items()})\r\n\r\n    def update_symbols(self, symbols):\r\n        self._globals.update(symbols)\r\n\r\n    def reset(self, context_item_names=None):\r\n        '''\r\n        Clears the computed values (as well as any user-provided values) in\r\n        preparation for the next cycle.\r\n        '''\r\n        self._locals = {}\r\n\r\n    def get_value(self, name, context=None):\r\n        if name not in self._locals:\r\n            self._evaluate_value(name, context)\r\n        return self._locals[name]\r\n\r\n    def get_values(self, names=None, context=None):\r\n        if names is None:\r\n            names = self._expressions.keys()\r\n        for name in names:\r\n            if name not in self._locals:\r\n                self._evaluate_value(name, context)\r\n        return dict(self._locals.copy())\r\n\r\n    def set_value(self, name, value):\r\n        _locals = self._locals.copy()\r\n        _locals[name] = value\r\n        self._locals = _locals\r\n\r\n    def set_values(self, values):\r\n        _locals = self._locals.copy()\r\n        _locals.update(values)\r\n        self._locals = _locals\r\n\r\n    def _evaluate_value(self, name, context=None):\r\n        if context is None:\r\n            context = {}\r\n\r\n        if name in context:\r\n            self._locals[name] = context[name]\r\n            return\r\n\r\n        expr = self._expressions[name]\r\n        c = self._globals.copy()\r\n        c.update(self._locals)\r\n        c.update(context)\r\n\r\n        # Build a context dictionary containing the dependencies required for\r\n        # evaluating the expression.\r\n        for d in expr._dependencies:\r\n            if d not in c and d in self._expressions:\r\n                c[d] = self.get_value(d, c)\r\n        \r\n        # Note that in the past I was forcing a copy of self._locals to ensure\r\n        # that the GUI was updated as needed; however, this proved to be a very\r\n        # slow process since it triggered a cascade of GUI updates. \r\n        self._locals[name] = expr.evaluate(c)\r\n","license":"mit","hash":6478125211385565033,"line_mean":30.8958333333,"line_max":83,"alpha_frac":0.5782140595,"autogenerated":false}
{"repo_name":"abrt\/faf","path":"src\/pyfaf\/utils\/contextmanager.py","copies":"1","size":"1078","content":"import sys\nfrom contextlib import contextmanager\n\nfrom io import StringIO\nfrom typing import Generator\nfrom _io import TextIOWrapper\n\n\n@contextmanager\ndef captured_output() -> Generator[TextIOWrapper, None, None]:\n    \"\"\"\n    Capture stdout and stderr output of the executed block\n\n    Example:\n\n    with captured_output() as (out, err):\n        foo()\n    \"\"\"\n\n    new_out, new_err = StringIO(), StringIO()\n    old_out, old_err = sys.stdout, sys.stderr\n    try:\n        sys.stdout, sys.stderr = new_out, new_err\n        yield sys.stdout, sys.stderr\n    finally:\n        sys.stdout, sys.stderr = old_out, old_err\n\n\n@contextmanager\ndef captured_output_combined() -> Generator[TextIOWrapper, None, None]:\n    \"\"\"\n    Capture stdout and stderr combined output of the executed block\n\n    Example:\n\n    with captured_output_combined() as out:\n        foo()\n    \"\"\"\n\n    new_out = StringIO()\n    old_out, old_err = sys.stdout, sys.stderr\n    try:\n        sys.stdout, sys.stderr = new_out, new_out\n        yield sys.stdout\n    finally:\n        sys.stdout, sys.stderr = old_out, old_err\n","license":"gpl-3.0","hash":-6979362351339216327,"line_mean":22.4347826087,"line_max":71,"alpha_frac":0.6484230056,"autogenerated":false}